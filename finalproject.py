# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/126EbTLcKhgdvu5BcACS8YbyWqOE-xR7f
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import GridSearchCV, train_test_split
import matplotlib.pyplot as plt

data_url = "https://raw.githubusercontent.com/brandinguyen/ece460j-finalproject/main/pokemon.csv"
data = pd.read_csv(data_url)
#print(data.describe())

plt.matshow(data.corr())

data = data.fillna(data.mean())

X = data.drop(columns = ['type1', 'abilities', 'japanese_name', 'name', 'type2', 'capture_rate', 'classfication'])
y = pd.get_dummies(data['type1']) # one-hot encode the primary type

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

#data.head()

from sklearn.feature_selection import VarianceThreshold

var_thres = VarianceThreshold(threshold = .1)
var_thres.fit(X_train)

constant_columns = [column for column in X_train.columns
                    if column not in X_train.columns[var_thres.get_support()]]

for feature in constant_columns:
  print(feature)

X_train.drop(constant_columns, axis = 1)
X_test.drop(constant_columns, axis = 1)

print(str(len(constant_columns)) + ' columns removed')

from sklearn import tree
from sklearn.metrics import accuracy_score

dtc = tree.DecisionTreeClassifier()
dtc = dtc.fit(X_train, y_train)
y_preds = dtc.predict(X_test)


print(y_preds)
accuracy_score(y_test, y_preds)

from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)
y_preds = rfc.predict(X_test)

print(y_preds)
accuracy_score(y_test, y_preds)

from xgboost import XGBClassifier

xgb = XGBClassifier()
xgb.fit(X_train, y_train)

y_preds = xgb.predict(X_test)
accuracy_score(y_test, y_preds)

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

dtc_gs = DecisionTreeClassifier()

params = {'criterion': ['gini', 'entropy'],
          'max_depth': [2, 4, 6, 8, 10, 11],
          'min_samples_split': [2, 4, 6, 8, 10],
          'min_samples_leaf': [1, 2, 3, 4, 5]}

grid = GridSearchCV(dtc_gs, params, cv=5)
grid.fit(X_train, y_train)

print("Best Hyperparameters:", grid.best_params_)
print("Best Score:", grid.best_score_)

from sklearn.metrics import accuracy_score

y_preds = grid.predict(X_test)
accuracy_score(y_test, y_preds)

from sklearn.ensemble import StackingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn import tree
from sklearn.metrics import accuracy_score

estimators = [('rf', RandomForestClassifier()),
              ('dtc', tree.DecisionTreeClassifier())]

clf = StackingClassifier(estimators=estimators)
#print(y_train)

clf.fit(X_train, y_train)
y_preds = clf.predict(X_test)

accuracy_score(y_test, y_preds)